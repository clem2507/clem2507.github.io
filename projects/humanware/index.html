<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Where Is My Stuff? | Clément Detry </title> <meta name="author" content="Clément Detry"> <meta name="description" content="Custom few-shot object detector for visually impaired people"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://clem2507.github.io/projects/humanware/"> <script src="/assets/js/theme.js?0e5ad416e456d624bbafab54da3a03df"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Clément</span> Detry </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Where Is My Stuff?</h1> <p class="post-description">Custom few-shot object detector for visually impaired people</p> </header> <article> <h2 id="overview">Overview</h2> <p>“Where Is My Stuff?” is an innovative project developed during my 16-month tenure at <a href="https://www.humanware.com/en-canada/home" target="_blank" rel="external nofollow noopener">HumanWare</a>, a company dedicated to creating devices that enhance the daily lives of visually impaired individuals. This project aimed to integrate advanced object detection capabilities into HumanWare’s <a href="https://store.humanware.com/hca/stellartrek.html" target="_blank" rel="external nofollow noopener">StellarTrek</a> device, a GPS-equipped camera system initially designed for navigation assistance.</p> <p>The primary goal was to develop a feature analogous to “FaceID” for iPhones, but tailored for locating personal objects. Unlike generic object detection, this system needed to identify specific items belonging to the user, such as their unique keys, wallet, or glasses. The challenge was to create a solution that could run efficiently on the StellarTrek’s Snapdragon 660 processor while addressing two key aspects:</p> <ol> <li>Enabling visually impaired users to easily capture support images of their objects.</li> <li>Implementing a robust detection pipeline for locating registered objects using few-shot images.</li> </ol> <hr> <h2 id="architecture">Architecture</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/humanware/wims_diagram.drawio.svg-480.webp 480w,/assets/img/humanware/wims_diagram.drawio.svg-800.webp 800w,/assets/img/humanware/wims_diagram.drawio.svg-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/humanware/wims_diagram.drawio.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="WIMS Diagram Architecture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Architecture diagram of the "Where Is My Stuff?" feature. </div> <h3 id="1-user-friendly-object-registration">1. User-Friendly Object Registration</h3> <p>To overcome the challenges faced by visually impaired users in representing the 3D world and feeling the camera angles, we developed an intuitive registration process:</p> <ol> <li>Users are instructed to touch the object first, creating a physical connection between the camera and the item.</li> <li>A detection model aims to detect overlapping hands and objects in the frame.</li> <li>The user interface provides step-by-step guidance through the capturing process based on real-time model predictions.</li> <li>Multiple images (5 to 10) are captured for each object to create a comprehensive support set.</li> </ol> <div class="row justify-content-center"> <div class="col-md-8 text-center"> <figure> <video src="/assets/video/humanware/object_registration.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> </div> </div> <div class="caption"> Demonstration of the object registration process. </div> <h3 id="2-custom-detection-pipeline">2. Custom Detection Pipeline</h3> <p>The heart of the “Where Is My Stuff?” feature is a custom-built detection pipeline designed to operate within the performance constraints of the StellarTrek device:</p> <ol> <li> <strong>Region Proposal Network (RPN)</strong>: A YOLOv8-nano object detector identifies potential object candidates in the scene.</li> <li> <strong>Embedding Network</strong>: A MobileNetV3-small backbone generates lower-dimension embeddings to represent objects, trained using a triplet loss approach for better object discrimination.</li> <li> <strong>Classification Model</strong>: A One-Class SVM model trained on support-set object embeddings performs anomaly detection, distinguishing between registered objects and other items.</li> <li> <strong>Single-Object Tracking (SOT)</strong>: Once an object is stably detected, the NanoTrackV3 model guides the user to its location using an audio feedback system.</li> </ol> <div class="row justify-content-center"> <div class="col-md-8 text-center"> <figure> <video src="/assets/video/humanware/object_detection.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> </div> </div> <div class="caption"> Demonstration of the few-shot object detection process. </div> <hr> <h2 id="key-features">Key Features</h2> <ul> <li> <strong>Few-shot learning</strong>: Ability to recognize specific objects from a small set of support images.</li> <li> <strong>On-device processing</strong>: All computations run locally on the StellarTrek’s Snapdragon 660 processor.</li> <li> <strong>User-friendly interface</strong>: Tailored for visually impaired users, with audio guidance and feedback.</li> <li> <strong>Adaptive object recognition</strong>: Learns and identifies user-specific items rather than generic object categories.</li> <li> <strong>Real-time tracking</strong>: Guides users to their objects using directional audio cues.</li> </ul> <p>This project demonstrates the potential of combining computer vision, machine learning, and user-centered design to create impactful solutions for individuals with visual impairments.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Clément Detry. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>